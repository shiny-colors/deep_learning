{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy.matlib\n",
    "import scipy.linalg\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "from scipy.stats import norm\n",
    "from numpy.random import *\n",
    "from scipy import optimize\n",
    "\n",
    "np.random.seed(98537)\n",
    "torch.manual_seed(98537)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多項分布の乱数を生成する関数\n",
    "def rmnom(pr, n, k, pattern):\n",
    "    if pattern==1:\n",
    "        z_id = np.array(np.argmax(np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis], axis=1), dtype=\"int\")\n",
    "        Z = np.diag(np.repeat(1, k))[z_id, ]\n",
    "        return z_id, Z\n",
    "    z_id = np.array(np.argmax((np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis]), axis=1), dtype=\"int\")\n",
    "    return z_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの生成\n",
    "# データの設定\n",
    "k = 12\n",
    "k_vec = np.repeat(1, k)\n",
    "hh = 5000\n",
    "item = 3000\n",
    "Lambda = np.random.gamma(40.0, 1/0.2, hh)\n",
    "pt = np.random.poisson(Lambda, hh)\n",
    "N = np.sum(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idとインデックスの設定\n",
    "# idの設定\n",
    "d_id = np.repeat(np.arange(hh), pt)\n",
    "pt_id = np.array(list(itertools.chain(*[np.array(range(pt[i]), dtype=\"int\") for i in range(hh)])))\n",
    "\n",
    "# インデックスの設定\n",
    "d_list = [i for i in range(hh)]\n",
    "for i in range(hh):\n",
    "    d_list[i] = np.array(np.where(d_id==i)[0], dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 素性ベクトルの生成\n",
    "k1 = 2; k2 = 4; k3 = 4\n",
    "x1 = np.random.normal(0.0, 0.5, k1*N).reshape(N, k1)\n",
    "x2 = np.zeros((N, k2))\n",
    "for j in range(k2):\n",
    "    prob = np.random.uniform(0.25, 0.55, 1)\n",
    "    x2[:, j] = np.random.binomial(1, prob, N)\n",
    "x3 = np.random.multinomial(1, np.random.dirichlet(np.repeat(2.5, k3), 1).reshape(k3), N)\n",
    "x3 = np.delete(x3, np.argmin(np.sum(x3, axis=0)), axis=1)   #冗長な変数の削除\n",
    "x = np.hstack((np.repeat(1.0, N)[:, np.newaxis], x1, x2, x3))\n",
    "col = x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アイテムの生成\n",
    "# 多項分布からトピックを生成\n",
    "topic = 30\n",
    "theta_topic = np.random.dirichlet(np.repeat(0.2, topic), hh)\n",
    "phi_topic = np.random.dirichlet(np.repeat(0.2, item), topic)\n",
    "z = rmnom(theta_topic[d_id, ], N, topic, 0)\n",
    "\n",
    "# トピックからアイテムを生成\n",
    "item_id = np.repeat(0, N)\n",
    "for i in range(hh):\n",
    "    index = d_list[i]\n",
    "    item_id[index] = rmnom(phi_topic[z[d_list[i]], ], pt[i], item, 0)\n",
    "    \n",
    "# インデックスの設定\n",
    "item_list = [i for i in range(item)]\n",
    "item_n = np.repeat(0, item)\n",
    "for i in range(item):\n",
    "    item_list[i] = np.array(np.where(item_id==i)[0], dtype=\"int\")\n",
    "    item_n[i] = item_list[i].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 応答変数の生成\n",
    "per_min = 75; per_max = 75\n",
    "rp = 0\n",
    "while True:\n",
    "    rp = rp + 1\n",
    "    \n",
    "    # 階層モデルのパラメータを生成\n",
    "    alpha = 0.0\n",
    "    alpha_u = np.repeat(0.0, k)\n",
    "    alpha_v = np.repeat(0.0, k)\n",
    "    Cov_u = np.diag(np.append(0.5, np.repeat(1.0, k)))\n",
    "    Cov_v = np.diag(np.append(0.7, np.repeat(1.0, k)))\n",
    "    Covt_u = Cov_u.copy(); Covt_v = Cov_v.copy()\n",
    "\n",
    "    # モデルパラメータを生成\n",
    "    beta = np.append(-1.0, np.random.normal(0.0, 0.7, col-1))\n",
    "    beta_u = np.random.normal(0.0, Cov_u[0, 0], hh)\n",
    "    beta_v = np.random.normal(0.0, Cov_v[0, 0], item)\n",
    "    theta_u = np.random.multivariate_normal(alpha_u, Cov_u[1:, 1:], hh)\n",
    "    theta_v = np.random.multivariate_normal(alpha_v, Cov_v[1:, 1:], item)\n",
    "    betat = beta.copy(); betat_u = beta_u.copy(); betat_v = beta_v.copy()\n",
    "    thetat_u = theta_u.copy(); thetat_v = theta_v.copy()\n",
    "        \n",
    "    # モデルの期待値\n",
    "    beta_mu = np.dot(x, beta)\n",
    "    uv = np.sum(theta_u[d_id, ] * theta_v[item_id, ], axis=1)\n",
    "    mu = beta_u[d_id] + beta_v[item_id] + beta_mu + uv\n",
    "    \n",
    "    #ベルヌーイ分布から応答変数を生成\n",
    "    Prob = np.exp(mu) / (1 + np.exp(mu))\n",
    "    y = np.random.binomial(1, Prob, N)\n",
    "    y_vec = y[:, np.newaxis]\n",
    "\n",
    "    #break条件\n",
    "    if (np.mean(y) > 0.2) & (np.mean(y) < 0.4):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#潜在変数ごとのヒストグラム\n",
    "dt = [Prob, mu, beta_u, beta_v, beta_mu, uv]\n",
    "fig_range = np.append(np.array([0, np.min(mu), np.min(beta_u), np.min(beta_v), np.min(beta_mu), np.min(uv)]), \n",
    "                      np.array([1.0, np.max(mu), np.max(beta_u), np.max(beta_v), np.max(beta_mu), np.max(uv)])).reshape(2, len(dt))\n",
    "colorlist = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]\n",
    "legend = [\"応答確率の分布\", \"モデル期待値の分布\", \"ユーザーバイアスの分布\", \"アイテムバイアスの分布\", \"素性ベクトルの分布\", \"uvの分布\"]\n",
    "fig = plt.figure(figsize=(12.5, 9.0))\n",
    "for j in range(len(dt)):\n",
    "    ax = fig.add_subplot(3, 2, j+1)\n",
    "    ax.hist(dt[j],  bins=25, range=(fig_range[0, j], fig_range[1, j]), color=colorlist[j])\n",
    "    plt.title(legend[j], fontsize=12.5)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの生成\n",
    "# ユーザーidの生成\n",
    "m = np.random.poisson(np.random.gamma(40.0, 1/0.2, hh))\n",
    "M = np.sum(m)\n",
    "d_id0 = np.repeat(np.arange(hh), m)\n",
    "\n",
    "# インデックスの設定\n",
    "d_list0 = [i for i in range(hh)]\n",
    "for i in range(hh):\n",
    "    d_list0[i] = np.array(np.where(d_id0==i)[0], dtype=\"int\")\n",
    "\n",
    "# 素性ベクトルを生成\n",
    "x1 = np.random.normal(0.0, 0.5, k1*M).reshape(M, k1)\n",
    "x2 = np.zeros((M, k2))\n",
    "for j in range(k2):\n",
    "    prob = np.random.uniform(0.25, 0.55, 1)\n",
    "    x2[:, j] = np.random.binomial(1, prob, M)\n",
    "x3 = np.random.multinomial(1, np.random.dirichlet(np.repeat(2.5, k3), 1).reshape(k3), M)\n",
    "x3 = np.delete(x3, np.argmin(np.sum(x3, axis=0)), axis=1)   #冗長な変数の削除\n",
    "x0 = np.hstack((np.repeat(1.0, M)[:, np.newaxis], x1, x2, x3))\n",
    "\n",
    "# アイテムの生成\n",
    "# 多項分布からトピックを生成\n",
    "z = rmnom(theta_topic[d_id0, ], M, topic, 0)\n",
    "\n",
    "# トピックからアイテムを生成\n",
    "item_id0 = np.repeat(0, M)\n",
    "for i in range(hh):\n",
    "    index = d_list0[i]\n",
    "    item_id0[index] = rmnom(phi_topic[z[d_list0[i]], ], m[i], item, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 応答変数の生成\n",
    "# モデルの期待値\n",
    "beta_mu = np.dot(x0, beta)\n",
    "uv = np.sum(theta_u[d_id0, ] * theta_v[item_id0, ], axis=1)\n",
    "mu = beta_u[d_id0] + beta_v[item_id0] + beta_mu + uv\n",
    "\n",
    "# ベルヌーイ分布から応答変数を生成\n",
    "Prob = np.exp(mu) / (1 + np.exp(mu))\n",
    "y0 = np.random.binomial(1, Prob, M)\n",
    "y_vec0 = y0[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対数尤度の基準値\n",
    "# 学習データの1パラメータモデルの対数尤度\n",
    "Prob = np.mean(y)\n",
    "LLst1 = np.sum(y*np.log(Prob)) + np.sum((1-y)*np.log(1-Prob))\n",
    "print(LLst1)\n",
    "\n",
    "# 学習データに対する真値の対数尤度\n",
    "mut = betat_u[d_id] + betat_v[item_id] + np.dot(x, betat) + np.dot(thetat_u[d_id, ] * thetat_v[item_id, ], k_vec)\n",
    "Prob = np.exp(mut) / (1 + np.exp(mut))\n",
    "LLbest1 = np.sum(y*np.log(Prob)) + np.sum((1-y)*np.log(1-Prob))\n",
    "print(LLbest1)\n",
    "\n",
    "# テストデータの1パラメータモデルの対数尤度\n",
    "Prob = np.mean(y0)\n",
    "LLst0 = np.sum(y0*np.log(Prob)) + np.sum((1-y0)*np.log(1-Prob))\n",
    "print(LLst0)\n",
    "\n",
    "# テストデータに対する真値の対数尤度\n",
    "mut = betat_u[d_id0] + betat_v[item_id0] + np.dot(x0, betat) + np.dot(thetat_u[d_id0, ] * thetat_v[item_id0, ], k_vec)\n",
    "Prob = np.exp(mut) / (1 + np.exp(mut))\n",
    "LLbest0 = np.sum(y0*np.log(Prob)) + np.sum((1-y0)*np.log(1-Prob))\n",
    "print(LLbest0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "# 対数尤度を定義\n",
    "def loglike(y, mu):\n",
    "    Prob = np.exp(mu) / (1 + np.exp(mu))\n",
    "    LL = np.sum(y*np.log(Prob) + (1-y)*np.log(1-Prob))\n",
    "    return LL\n",
    "\n",
    "# LRLFMの定義\n",
    "class LRLF(nn.Module):\n",
    "    def __init__(self, col, k, hh, item):\n",
    "        super().__init__()\n",
    "        self.beta = nn.Linear(in_features=col, out_features=1, bias=False)\n",
    "        self.beta_u = nn.Embedding(num_embeddings=hh, embedding_dim=1)\n",
    "        self.beta_v = nn.Embedding(num_embeddings=item, embedding_dim=1)\n",
    "        self.theta_u = nn.Embedding(num_embeddings=hh, embedding_dim=k)\n",
    "        self.theta_v = nn.Embedding(num_embeddings=item, embedding_dim=k)\n",
    "        self.mu = nn.Linear(in_features=1, out_features=1, bias=False)\n",
    "        \n",
    "    def forward(self, x, d_id, item_id, N):\n",
    "        beta_mu = self.beta(x)\n",
    "        beta_user = self.beta_u(d_id)\n",
    "        beta_item = self.beta_v(item_id)\n",
    "        uv = (self.theta_u(d_id) * self.theta_v(item_id)).sum(1).reshape(N, 1)\n",
    "        mu = self.mu(beta_mu + beta_user + beta_item + uv)\n",
    "        return mu\n",
    "    \n",
    "# 早期終了アルゴリズム\n",
    "class EarlyStopping:\n",
    "    '''\n",
    "    早期終了 (early stopping)\n",
    "    '''\n",
    "    def __init__(self, patience=0, verbose=0):\n",
    "        self._step = 0\n",
    "        self._loss = float('inf')\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __call__(self, loss):\n",
    "        if self._loss < loss:\n",
    "            self._step += 1\n",
    "            if self._step > self.patience:\n",
    "                if self.verbose:\n",
    "                    print('early stopping')\n",
    "                return True\n",
    "        else:\n",
    "            self._step = 0\n",
    "            self._loss = loss\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習\n",
    "# アルゴリズムの定義\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LRLF(col, k, hh, item).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"sum\")\n",
    "optimizer = optimizers.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999), amsgrad=True, weight_decay=0.1)\n",
    "\n",
    "def compute_loss(t, y):\n",
    "    return criterion(t, y)\n",
    "\n",
    "def train_step(y, x, d_id, item_id, model, optimizer):\n",
    "    model.train()\n",
    "    mu = model(x, d_id, item_id, x.shape[0])\n",
    "    Lho = compute_loss(mu.reshape(-1), y)\n",
    "    optimizer.zero_grad()\n",
    "    Lho.backward()\n",
    "    optimizer.step()\n",
    "    return Lho, mu\n",
    "\n",
    "def val_step(y0, x0, d_id0, item_id0, model):\n",
    "    model.eval()\n",
    "    mu = model(x0, d_id0, item_id0, x0.shape[0])\n",
    "    Lho = compute_loss(mu.reshape(-1), y0)\n",
    "    return Lho, mu\n",
    "\n",
    "# モデルの設定\n",
    "epochs = 50\n",
    "batch_size = 10000\n",
    "n_batches_train = N // batch_size\n",
    "n_batches_val = M // batch_size\n",
    "es = EarlyStopping(patience=5, verbose=1)\n",
    "hist = {\"train_loglike\": [], \"val_loglike\" : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tensor型の配列を定義\n",
    "x = torch.Tensor(x)\n",
    "y = torch.Tensor(y)\n",
    "d_id = torch.LongTensor(d_id)\n",
    "item_id = torch.LongTensor(item_id)\n",
    "x0_ = torch.Tensor(x0).to(device)\n",
    "y0_ = torch.Tensor(y0).to(device)\n",
    "d_id0_ = torch.LongTensor(d_id0).to(device)\n",
    "item_id0_ = torch.LongTensor(item_id0).to(device)\n",
    "\n",
    "# 確率的勾配法でモデルを推定\n",
    "for rp in range(epochs):\n",
    "    \n",
    "    # データの定義\n",
    "    random_index = np.argsort(np.random.uniform(0, 1, N))\n",
    "    x_ = x[random_index, ].to(device)\n",
    "    y_ = y[random_index].to(device)\n",
    "    d_id_ = d_id[random_index].to(device)\n",
    "    item_id_ = item_id[random_index].to(device)\n",
    "\n",
    "    # パラメータを更新\n",
    "    preds_train = np.array([])\n",
    "    for batch in range(n_batches_train):\n",
    "        start = batch * batch_size\n",
    "        if batch==n_batches_train-1:\n",
    "            end = x.shape[0]\n",
    "        else:\n",
    "            end = start + batch_size\n",
    "        \n",
    "        Lho, mu = train_step(y_[start:end], x_[start:end, ], d_id_[start:end, ], item_id_[start:end, ], model, optimizer)\n",
    "        preds_train = np.append(preds_train, mu.cpu().detach().numpy().reshape(-1))\n",
    "\n",
    "    # 学習データの対数尤度を更新\n",
    "    preds_ = torch.Tensor(preds_train).to(device)\n",
    "    train_loglike = loglike(y_.to(\"cpu\").numpy(), preds_.to(\"cpu\").numpy())\n",
    "    hist[\"train_loglike\"].append(train_loglike)\n",
    "    \n",
    "    \n",
    "    # テストデータの予測値を更新\n",
    "    preds_val = np.array([])\n",
    "    for batch in range(n_batches_val):\n",
    "        start = batch * batch_size\n",
    "        if batch==n_batches_train-1:\n",
    "            end = x0.shape[0]\n",
    "        else:\n",
    "            end = start + batch_size\n",
    "        Lho, mu = val_step(y0_[start:end], x0_[start:end], d_id0_[start:end], item_id0_[start:end], model)\n",
    "        preds_val = np.append(preds_val, mu.cpu().detach().numpy().reshape(-1))\n",
    "    \n",
    "    # テストデータの対数尤度を更新\n",
    "    preds_ = torch.Tensor(preds_val).to(device)\n",
    "    val_loglike = loglike(y0_.to(\"cpu\").numpy(), preds_.to(\"cpu\").numpy())\n",
    "    hist[\"val_loglike\"].append(val_loglike)\n",
    "    \n",
    "    # 学習結果を表示\n",
    "    print(rp)\n",
    "    print(np.round([train_loglike, val_loglike], 1))\n",
    "    \n",
    "    # 早期終了\n",
    "    if es(-val_loglike)==True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
