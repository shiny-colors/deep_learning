{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "import torchtext\n",
    "import glob\n",
    "import os\n",
    "import io\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from torchtext.vocab import Vectors\n",
    "from utils.dataloader import get_IMDb_DataLoaders_and_TEXT\n",
    "\n",
    "np.random.seed(9837)\n",
    "torch.manual_seed(9837)\n",
    "pd.set_option(\"display.max_rows\", 250)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理の関数\n",
    "def preprocessing_text(text):\n",
    "    # 改行コードを消去\n",
    "    text = re.sub('<br />', '', text)\n",
    "\n",
    "    # カンマ、ピリオド以外の記号をスペースに置換\n",
    "    for p in string.punctuation:\n",
    "        if (p == \".\") or (p == \",\"):\n",
    "            continue\n",
    "        else:\n",
    "            text = text.replace(p, \" \")\n",
    "\n",
    "    # ピリオドなどの前後にはスペースを入れておく\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    return text\n",
    "\n",
    "# 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
    "def tokenizer_punctuation(text):\n",
    "    return text.strip().split()\n",
    "\n",
    "\n",
    "# 前処理と分かち書きをまとめた関数を定義\n",
    "def tokenizer_with_preprocessing(text):\n",
    "    text = preprocessing_text(text)\n",
    "    ret = tokenizer_punctuation(text)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データのtsvファイルを作成\n",
    "path = \"D:/Statistics/data/deep_leraning/nlp/\"\n",
    "\n",
    "f = open(path + \"IMDb_train.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "positive_path = path + \"aclImdb/train/pos/\"\n",
    "for fname in glob.glob(os.path.join(positive_path, \"*.txt\")):\n",
    "    with io.open(fname, \"r\", encoding=\"utf-8\") as ff:\n",
    "        text = ff.readline()\n",
    "\n",
    "        # タブがあれば消去\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "\n",
    "        text = text+\"\\t\"+\"1\"+\"\\t\"+\"\\n\"\n",
    "        f.write(text)\n",
    "\n",
    "negative_path = path + \"aclImdb/train/neg/\"\n",
    "for fname in glob.glob(os.path.join(negative_path, \"*.txt\")):\n",
    "    with io.open(fname, \"r\", encoding=\"utf-8\") as ff:\n",
    "        text = ff.readline()\n",
    "\n",
    "        # タブがあれば消去\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "\n",
    "        text = text+\"\\t\"+\"0\"+\"\\t\"+\"\\n\"\n",
    "        f.write(text)\n",
    "\n",
    "f.close()\n",
    "\n",
    "# テストデータのtsvファイルを作成\n",
    "f = open(path + \"IMDb_test.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "positive_path = path + \"aclImdb/test/pos/\"\n",
    "for fname in glob.glob(os.path.join(positive_path, \"*.txt\")):\n",
    "    with io.open(fname, \"r\", encoding=\"utf-8\") as ff:\n",
    "        text = ff.readline()\n",
    "\n",
    "        # タブがあれば消去\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "\n",
    "        text = text+\"\\t\"+\"1\"+\"\\t\"+\"\\n\"\n",
    "        f.write(text)\n",
    "\n",
    "negative_path = path + \"aclImdb/test/neg/\"\n",
    "for fname in glob.glob(os.path.join(negative_path, \"*.txt\")):\n",
    "    with io.open(fname, \"r\", encoding=\"utf-8\") as ff:\n",
    "        text = ff.readline()\n",
    "\n",
    "        # タブがあれば消去\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "\n",
    "        text = text+\"\\t\"+\"0\"+\"\\t\"+\"\\n\"\n",
    "        f.write(text)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textとラベルを定義\n",
    "# 文章とラベルの両方を用意\n",
    "max_length=256\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
    "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, \n",
    "                            init_token=\"<cls>\", eos_token=\"<eos>\")\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "# フォルダ「data」からtsvファイルを読み込み\n",
    "train_val_ds, test_ds = torchtext.data.TabularDataset.splits(path=path, train=\"IMDb_train.tsv\", test=\"IMDb_test.tsv\", format=\"tsv\",\n",
    "                                                             fields=[(\"Text\", TEXT), (\"Label\", LABEL)])\n",
    "\n",
    "# torchtext.data.Datasetのsplit関数で訓練データと検証データに分割\n",
    "train_ds, val_ds = train_val_ds.split(split_ratio=0.8, random_state=random.seed(1234))\n",
    "\n",
    "\n",
    "# ボキャブラリーを作成\n",
    "# torchtextで単語ベクトルとして英語学習済みモデルを読み込み\n",
    "load_path = path + \"wiki-news-300d-1M.vec\" \n",
    "english_fasttext_vectors = Vectors(name=load_path)\n",
    "\n",
    "# ベクトル化したバージョンのボキャブラリーを作成\n",
    "TEXT.build_vocab(train_ds, vectors=english_fasttext_vectors, min_freq=10)\n",
    "\n",
    "# DataLoaderを作成\n",
    "batch_size=24\n",
    "train_dl = torchtext.data.Iterator(train_ds, batch_size=batch_size, train=True)\n",
    "val_dl = torchtext.data.Iterator(test_ds, batch_size=batch_size, train=False, sort=False)\n",
    "test_dl = torchtext.data.Iterator(test_ds, batch_size=batch_size, train=False, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformerのblockを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding層を定義\n",
    "class Embedder(nn.Module):\n",
    "    # idで示される単語をベクトルに変換\n",
    "    \n",
    "    def __init__(self, text_embedding_vectors):\n",
    "        super(Embedder, self).__init__()\n",
    "        \n",
    "        # 学習済み単語ベクトルを読み込み(freeze=Trueで学習しない)\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings=text_embedding_vectors, freeze=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_vec = self.embedding(x)\n",
    "        return x_vec        \n",
    "    \n",
    "# 動作を確認\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_IMDb_DataLoaders_and_TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import io\n",
    "import string\n",
    "import re\n",
    "import torchtext\n",
    "import random\n",
    "from torchtext.vocab import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データのtsvファイルを作成します\n",
    "f = open(path + \"IMDb_train.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "positive_path = path + \"aclImdb/train/pos/\"\n",
    "for fname in glob.glob(os.path.join(positive_path, \"*.txt\")):\n",
    "    with io.open(fname, \"r\", encoding=\"utf-8\") as ff:\n",
    "        text = ff.readline()\n",
    "\n",
    "        # タブがあれば消去\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "\n",
    "        text = text+\"\\t\"+\"1\"+\"\\t\"+\"\\n\"\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
