{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1579723b6f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ライブラリのインポート\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの生成\n",
    "N = 300\n",
    "x, t = datasets.make_moons(N, 0.3)\n",
    "t = t[:, np.newaxis]\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多層パーセプトロン\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim, output_dim)\n",
    "        self.a1 = nn.Sigmoid()\n",
    "        self.l2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.a2 = nn.Sigmoid()\n",
    "        self.layers = [self.l1, self.a1, self.l2, self.a2]\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習\n",
    "# アルゴリズムの定義\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(2, 3, 1).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optimizers.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "def compute_loss(t, y):\n",
    "    return criterion(y, t)\n",
    "\n",
    "def train_step(x, t):\n",
    "    model.train()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "# アルゴリズムの設定\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "n_batches = x_train.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 16.5\n",
      "epoch: 2, loss: 16.0\n",
      "epoch: 3, loss: 15.6\n",
      "epoch: 4, loss: 15.2\n",
      "epoch: 5, loss: 14.7\n",
      "epoch: 6, loss: 14.2\n",
      "epoch: 7, loss: 13.6\n",
      "epoch: 8, loss: 13.1\n",
      "epoch: 9, loss: 12.6\n",
      "epoch: 10, loss: 12.1\n",
      "epoch: 11, loss: 11.6\n",
      "epoch: 12, loss: 11.2\n",
      "epoch: 13, loss: 10.8\n",
      "epoch: 14, loss: 10.4\n",
      "epoch: 15, loss: 10.1\n",
      "epoch: 16, loss: 9.81\n",
      "epoch: 17, loss: 9.54\n",
      "epoch: 18, loss: 9.29\n",
      "epoch: 19, loss: 9.08\n",
      "epoch: 20, loss: 8.87\n",
      "epoch: 21, loss: 8.67\n",
      "epoch: 22, loss: 8.51\n",
      "epoch: 23, loss: 8.33\n",
      "epoch: 24, loss: 8.17\n",
      "epoch: 25, loss: 8.05\n",
      "epoch: 26, loss: 7.92\n",
      "epoch: 27, loss: 7.8\n",
      "epoch: 28, loss: 7.68\n",
      "epoch: 29, loss: 7.56\n",
      "epoch: 30, loss: 7.47\n",
      "epoch: 31, loss: 7.37\n",
      "epoch: 32, loss: 7.28\n",
      "epoch: 33, loss: 7.19\n",
      "epoch: 34, loss: 7.12\n",
      "epoch: 35, loss: 7.05\n",
      "epoch: 36, loss: 6.98\n",
      "epoch: 37, loss: 6.93\n",
      "epoch: 38, loss: 6.86\n",
      "epoch: 39, loss: 6.81\n",
      "epoch: 40, loss: 6.77\n",
      "epoch: 41, loss: 6.73\n",
      "epoch: 42, loss: 6.68\n",
      "epoch: 43, loss: 6.65\n",
      "epoch: 44, loss: 6.61\n",
      "epoch: 45, loss: 6.57\n",
      "epoch: 46, loss: 6.53\n",
      "epoch: 47, loss: 6.5\n",
      "epoch: 48, loss: 6.48\n",
      "epoch: 49, loss: 6.47\n",
      "epoch: 50, loss: 6.44\n",
      "epoch: 51, loss: 6.41\n",
      "epoch: 52, loss: 6.39\n",
      "epoch: 53, loss: 6.39\n",
      "epoch: 54, loss: 6.34\n",
      "epoch: 55, loss: 6.33\n",
      "epoch: 56, loss: 6.32\n",
      "epoch: 57, loss: 6.3\n",
      "epoch: 58, loss: 6.3\n",
      "epoch: 59, loss: 6.28\n",
      "epoch: 60, loss: 6.26\n",
      "epoch: 61, loss: 6.27\n",
      "epoch: 62, loss: 6.24\n",
      "epoch: 63, loss: 6.24\n",
      "epoch: 64, loss: 6.23\n",
      "epoch: 65, loss: 6.21\n",
      "epoch: 66, loss: 6.22\n",
      "epoch: 67, loss: 6.19\n",
      "epoch: 68, loss: 6.19\n",
      "epoch: 69, loss: 6.2\n",
      "epoch: 70, loss: 6.19\n",
      "epoch: 71, loss: 6.19\n",
      "epoch: 72, loss: 6.17\n",
      "epoch: 73, loss: 6.17\n",
      "epoch: 74, loss: 6.15\n",
      "epoch: 75, loss: 6.17\n",
      "epoch: 76, loss: 6.17\n",
      "epoch: 77, loss: 6.15\n",
      "epoch: 78, loss: 6.15\n",
      "epoch: 79, loss: 6.13\n",
      "epoch: 80, loss: 6.13\n",
      "epoch: 81, loss: 6.14\n",
      "epoch: 82, loss: 6.12\n",
      "epoch: 83, loss: 6.13\n",
      "epoch: 84, loss: 6.12\n",
      "epoch: 85, loss: 6.12\n",
      "epoch: 86, loss: 6.11\n",
      "epoch: 87, loss: 6.12\n",
      "epoch: 88, loss: 6.1\n",
      "epoch: 89, loss: 6.12\n",
      "epoch: 90, loss: 6.12\n",
      "epoch: 91, loss: 6.1\n",
      "epoch: 92, loss: 6.11\n",
      "epoch: 93, loss: 6.11\n",
      "epoch: 94, loss: 6.1\n",
      "epoch: 95, loss: 6.11\n",
      "epoch: 96, loss: 6.11\n",
      "epoch: 97, loss: 6.1\n",
      "epoch: 98, loss: 6.1\n",
      "epoch: 99, loss: 6.1\n",
      "epoch: 100, loss: 6.09\n"
     ]
    }
   ],
   "source": [
    "# 確率的勾配法でモデルを学習\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    x_, t_ = shuffle(x_train, t_train)\n",
    "    x_ = torch.Tensor(x_).to(device)\n",
    "    t_ = torch.Tensor(t_).to(device)\n",
    "\n",
    "    for n_batch in range(n_batches):\n",
    "        start = n_batch * batch_size\n",
    "        end = start + batch_size\n",
    "        loss = train_step(x_[start:end], t_[start:end])\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(\"epoch: {}, loss: {:.3}\".format(epoch+1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの評価\n",
    "def test_step(x, t):\n",
    "    x = torch.Tensor(x).to(device)\n",
    "    t = torch.Tensor(t).to(device)\n",
    "    model.eval()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "    return loss, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2655848562717438 0.9\n"
     ]
    }
   ],
   "source": [
    "loss, preds = test_step(x_test, t_test)\n",
    "test_loss = loss.item()\n",
    "preds = preds.data.cpu().numpy() > 0.5\n",
    "test_acc = accuracy_score(t_test, preds)\n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
